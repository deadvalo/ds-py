{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837e4de3",
   "metadata": {},
   "source": [
    "### This notebook aims at providing a pipeline for a random forest classifier but can be used for any model of the sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a44eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from skimage.feature import hog\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a674582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please change the directories to the one where you downloaded the datasets\n",
    "train_dir = \"C:/Users/thoma/OneDrive/Desktop/Centrale/3A/Spé info/SID/Méthodo/Projet/training\"\n",
    "val_dir = \"C:/Users/thoma/OneDrive/Desktop/Centrale/3A/Spé info/SID/Méthodo/Projet/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823c55f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We resize the images to a 256x256 format\n",
    "def resize_image(img):\n",
    "    res = img.resize((256,256),Image.BICUBIC)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443fb0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating features (flattened image and its HOG)\n",
    "def create_features(img):\n",
    "    color_features = np.array(img).flatten()\n",
    "    # convert image to greyscale\n",
    "    gray_image = ImageOps.grayscale(img)\n",
    "    # get HOG features from greyscale image\n",
    "    hog_features = hog(np.array(gray_image), block_norm='L2-Hys', pixels_per_cell=(16, 16))\n",
    "    # combine color and hog features into a single array\n",
    "    flat_features = np.hstack([color_features, hog_features])\n",
    "    return flat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a03bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We finalize creating the features for a sklearn model\n",
    "def flatten_and_create_features(X):\n",
    "    features_list = []\n",
    "    for img in X:\n",
    "        flat_features = create_features(img)\n",
    "        features_list.append(flat_features)\n",
    "    return np.array(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5bb518",
   "metadata": {},
   "source": [
    "We decided to add supplementary and relevent features (namely the HOG of the images) to help the machine learning models because they are not designed specifically for object recognition conversely to CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee14ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a class for loading and creating the training and validation datasets\n",
    "class DataLoader:\n",
    "    def __init__(self, train_dir, val_dir):\n",
    "        self.train_dir = train_dir\n",
    "        self.val_dir = val_dir\n",
    "        \n",
    "    def load_data(self):\n",
    "        Training_img = []\n",
    "        \n",
    "        Dmg_train_dir = self.train_dir + \"/00-damage\"\n",
    "        \n",
    "        for images in os.listdir(Dmg_train_dir):\n",
    "            im = Image.open(Dmg_train_dir + '/' + images)\n",
    "            Training_img.append([im,1])\n",
    "            \n",
    "        Whole_train_dir = self.train_dir + \"/01-whole\"\n",
    "        \n",
    "        for images in os.listdir(Whole_train_dir):\n",
    "            im = Image.open(Whole_train_dir + '/' + images)\n",
    "            Training_img.append([im,0])\n",
    "            \n",
    "        random.shuffle(Training_img)\n",
    "        \n",
    "        #We needed to take images and labels as a whole as to shuffle them so as to avoid any bias when training models\n",
    "        \n",
    "        X_train,y_train = [],[]\n",
    "        \n",
    "        for k in Training_img:\n",
    "            X_train.append(k[0])\n",
    "            y_train.append(k[1])\n",
    "            \n",
    "        X_train_res = [resize_image(img) for img in X_train]\n",
    "        X_train_SK = flatten_and_create_features(X_train_res)\n",
    "        y_train_SK = np.array(y_train)\n",
    "        \n",
    "        Validation_img = []\n",
    "        \n",
    "        Dmg_val_dir = self.val_dir + \"/00-damage\"\n",
    "        \n",
    "        for images in os.listdir(Dmg_val_dir):\n",
    "            im = Image.open(Dmg_val_dir + '/' + images)\n",
    "            Validation_img.append([im,1])\n",
    "            \n",
    "        Whole_val_dir = self.val_dir + \"/01-whole\"\n",
    "        \n",
    "        for images in os.listdir(Whole_val_dir):\n",
    "            im = Image.open(Whole_val_dir + '/' + images)\n",
    "            Validation_img.append([im,0])\n",
    "            \n",
    "        random.shuffle(Validation_img)\n",
    "        \n",
    "        #Same reason as above for this part of the code\n",
    "        \n",
    "        X_val, y_val = [], []\n",
    "        \n",
    "        for k in Validation_img:\n",
    "            X_val.append(k[0])\n",
    "            y_val.append(k[1])\n",
    "            \n",
    "        X_val_res = [resize_image(img) for img in X_val]\n",
    "        X_val_SK = flatten_and_create_features(X_val_res)\n",
    "        y_val_SK = np.array(y_val)\n",
    "        \n",
    "        return X_train_SK, y_train_SK, X_val_SK, y_val_SK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "956b26fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bcbed05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline to the training data\n",
    "X_train, y_train, X_val, y_val = DataLoader(train_dir, val_dir).load_data()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f27e1231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.808695652173913\n"
     ]
    }
   ],
   "source": [
    "#We compute the accuracy for the validation set\n",
    "accuracy = model.score(X_val, y_val)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
